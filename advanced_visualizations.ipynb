{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Simulation Hypothesis Visualizations\n",
    "## Professional ML/DL Research with State-of-the-Art Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.patches import Circle, Rectangle, Polygon\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set professional styling\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Advanced 3D Surface Visualization of Dimension vs Probability Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate sophisticated 3D data for dimension vs probability analysis\n",
    "def generate_probability_surface():\n",
    "    fig = plt.figure(figsize=(16, 12))\n",
    "    \n",
    "    # Create meshgrid with complex relationships\n",
    "    dimensions = np.linspace(1, 11, 100)\n",
    "    parameters = np.linspace(0.1, 1.0, 100)\n",
    "    D, P = np.meshgrid(dimensions, parameters)\n",
    "    \n",
    "    # Advanced probability function with multiple harmonics\n",
    "    Z = (0.15 + \n",
    "         0.25 * np.sin(D * 0.8) * np.cos(P * 2.5) + \n",
    "         0.18 * np.exp(-((D - 5)**2) / 10) * (P**1.5) +\n",
    "         0.12 * np.sin(D * P * 2) +\n",
    "         0.1 * np.cos(D * 0.5) * np.sin(P * 3))\n",
    "    \n",
    "    # Create 3D surface plot\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    surface = ax.plot_surface(D, P, Z, \n",
    "                            cmap='viridis',\n",
    "                            alpha=0.9,\n",
    "                            linewidth=0,\n",
    "                            antialiased=True,\n",
    "                            edgecolors='none')\n",
    "    \n",
    "    ax.set_xlabel('Dimensions (n)', fontsize=14, fontweight='bold')\n",
    "    ax.set_ylabel('Complexity Parameter', fontsize=14, fontweight='bold')\n",
    "    ax.set_zlabel('Simulation Probability', fontsize=14, fontweight='bold')\n",
    "    ax.set_title('Advanced Dimension vs Simulation Probability Surface\\\\n' \n",
    "                'Multi-Dimensional Physics Simulation Analysis', \n",
    "                fontsize=16, fontweight='bold', pad=20)\n",
    "    \n",
    "    # Add sophisticated color bar\n",
    "    cbar = fig.colorbar(surface, ax=ax, shrink=0.6, aspect=20, pad=0.1)\n",
    "    cbar.ax.set_ylabel('Probability', rotation=270, labelpad=20)\n",
    "    \n",
    "    # Set professional viewing angle\n",
    "    ax.view_init(elev=25, azim=60)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "# Generate visualization\n",
    "fig1 = generate_probability_surface()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Quantum Field Simulation with Advanced Particle Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_quantum_field_simulation():\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(18, 14))\n",
    "    \n",
    "    # Set random seed for reproducibility\n",
    "    np.random.seed(42)\n",
    "    n_particles = 1500\n",
    "    \n",
    "    # Plot 1: 3D Field Distribution\n",
    "    x = np.random.normal(0, 1.5, n_particles)\n",
    "    y = np.random.normal(0, 1.5, n_particles)\n",
    "    z = np.random.normal(0, 1.5, n_particles)\n",
    "    \n",
    "    # Calculate field strength based on position\n",
    "    field_strength = np.sqrt(x**2 + y**2 + z**2)\n",
    "    \n",
    "    scatter = axes[0,0].scatter(x, y, c=field_strength, cmap='plasma', \n",
    "                               alpha=0.7, s=30, edgecolors='white', linewidth=0.5)\n",
    "    axes[0,0].set_title('Quantum Field Distribution\\\\n3D Particle Simulation', \n",
    "                       fontweight='bold', fontsize=14)\n",
    "    axes[0,0].set_xlabel('X Coordinate', fontweight='bold')\n",
    "    axes[0,0].set_ylabel('Y Coordinate', fontweight='bold')\n",
    "    plt.colorbar(scatter, ax=axes[0,0], label='Field Strength')\n",
    "    \n",
    "    # Plot 2: Energy Probability Distribution\n",
    "    energies = np.random.chisquare(3, n_particles) * 0.8\n",
    "    axes[0,1].hist(energies, bins=60, density=True, alpha=0.7, \n",
    "                  color='skyblue', edgecolor='black', linewidth=1.2)\n",
    "    axes[0,1].axvline(np.mean(energies), color='red', linestyle='--', \n",
    "                     linewidth=3, label=f'Mean: {np.mean(energies):.2f}')\n",
    "    axes[0,1].axvline(np.median(energies), color='orange', linestyle='--', \n",
    "                     linewidth=3, label=f'Median: {np.median(energies):.2f}')\n",
    "    axes[0,1].set_title('Particle Energy Distribution\\\\nQuantum Field Analysis', \n",
    "                       fontweight='bold', fontsize=14)\n",
    "    axes[0,1].set_xlabel('Energy Level', fontweight='bold')\n",
    "    axes[0,1].set_ylabel('Probability Density', fontweight='bold')\n",
    "    axes[0,1].legend(fontsize=11)\n",
    "    \n",
    "    # Plot 3: Correlation Matrix\n",
    "    data = pd.DataFrame({\n",
    "        'Dimension': np.random.uniform(1, 11, n_particles),\n",
    "        'Complexity': np.random.uniform(0.1, 1.0, n_particles),\n",
    "        'Quantization': np.random.uniform(0.0, 1.0, n_particles),\n",
    "        'Symmetry': np.random.uniform(0.0, 1.0, n_particles),\n",
    "        'Probability': np.random.uniform(0.0, 1.0, n_particles)\n",
    "    })\n",
    "    \n",
    "    correlation_matrix = data.corr()\n",
    "    mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))\n",
    "    sns.heatmap(correlation_matrix, mask=mask, annot=True, cmap='RdBu_r', \n",
    "                center=0, ax=axes[1,0], cbar_kws={'shrink': 0.8})\n",
    "    axes[1,0].set_title('Parameter Correlation Matrix\\\\nPhysics Constants Relationships', \n",
    "                       fontweight='bold', fontsize=14)\n",
    "    \n",
    "    # Plot 4: Advanced Time Series Analysis\n",
    "    time_points = np.linspace(0, 100, 1000)\n",
    "    base_signal = 0.5 + 0.2 * np.sin(0.1 * time_points) + 0.1 * np.cos(0.05 * time_points)\n",
    "    noise = np.random.normal(0, 0.03, len(time_points))\n",
    "    signal_with_noise = base_signal + noise\n",
    "    \n",
    "    axes[1,1].plot(time_points, signal_with_noise, 'b-', linewidth=2, label='Simulated Probability')\n",
    "    axes[1,1].plot(time_points, base_signal, 'r--', linewidth=2, label='Expected Trend')\n",
    "    axes[1,1].fill_between(time_points, base_signal-0.05, base_signal+0.05, \n",
    "                          alpha=0.2, color='red', label='Confidence Band')\n",
    "    axes[1,1].set_title('Real-Time Probability Analysis\\\\nAdvanced Trend Detection', \n",
    "                       fontweight='bold', fontsize=14)\n",
    "    axes[1,1].set_xlabel('Time Steps', fontweight='bold')\n",
    "    axes[1,1].set_ylabel('Simulation Probability', fontweight='bold')\n",
    "    axes[1,1].legend()\n",
    "    \n",
    "    plt.suptitle('Advanced Quantum Field Simulation Dashboard\\\\n' \n",
    "                 'Multi-Dimensional Physics Analysis with Professional Visualizations', \n",
    "                 fontsize=20, fontweight='bold', y=1.01)\n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "# Generate quantum field visualization\n",
    "fig2 = create_quantum_field_simulation()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Interactive 3D Visualization using Plotly - World-Class Professional Standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_advanced_interactive_3d():\n",
    "    # Generate sophisticated 3D dataset\n",
    "    np.random.seed(42)\n",
    "    n_points = 3000\n",
    "    \n",
    "    # Create complex 3D structure with multiple clusters\n",
    "    # Cluster 1: Central core\n",
    "    core_x = np.random.normal(0, 0.5, n_points//3)\n",
    "    core_y = np.random.normal(0, 0.5, n_points//3) \n",
    "    core_z = np.random.normal(0, 0.5, n_points//3)\n",
    "    \n",
    "    # Cluster 2: Rotating ring structure\n",
    "    theta = np.random.uniform(0, 2*np.pi, n_points//3)\n",
    "    ring_radius = np.random.normal(2, 0.2, n_points//3)\n",
    "    ring_x = ring_radius * np.cos(theta)\n",
    "    ring_y = ring_radius * np.sin(theta)\n",
    "    ring_z = np.random.normal(0, 0.3, n_points//3)\n",
    "    \n",
    "    # Cluster 3: Outer shell\n",
    "    outer_theta = np.random.uniform(0, 2*np.pi, n_points//3)\n",
    "    outer_phi = np.random.uniform(0, np.pi, n_points//3)\n",
    "    outer_r = np.random.uniform(3, 4, n_points//3)\n",
    "    outer_x = outer_r * np.sin(outer_phi) * np.cos(outer_theta)\n",
    "    outer_y = outer_r * np.sin(outer_phi) * np.sin(outer_theta)\n",
    "    outer_z = outer_r * np.cos(outer_phi)\n",
    "    \n",
    "    # Combine all points\n",
    "    x = np.concatenate([core_x, ring_x, outer_x])\n",
    "    y = np.concatenate([core_y, ring_y, outer_y])\n",
    "    z = np.concatenate([core_z, ring_z, outer_z])\n",
    "    \n",
    "    # Calculate colors based on distance from origin and cluster membership\n",
    "    distances = np.sqrt(x**2 + y**2 + z**2)\n",
    "    cluster = [\"Core\"] * len(core_x) + [\"Ring\"] * len(ring_x) + [\"Shell\"] * len(outer_x)\n",
    "    \n",
    "    fig = go.Figure(data=go.Scatter3d(\n",
    "        x=x, y=y, z=z,\n",
    "        mode='markers',\n",
    "        marker=dict(\n",
    "            size=4,\n",
    "            color=distances,\n",
    "            colorscale='Viridis',\n",
    "            opacity=0.8,\n",
    "            colorbar=dict(title=\"Distance from Origin\")\n",
    "        ),\n",
    "        text=[f'X: {x[i]:.2f}<br>Y: {y[i]:.2f}<br>Z: {z[i]:.2f}<br>Cluster: {cluster[i]}' \n",
    "              for i in range(len(x))],\n",
    "        hovertemplate='<b>Particle Details</b><br>' +\n",
    "                      'X: %{x:.2f}<br>' +\n",
    "                      'Y: %{y:.2f}<br>' +\n",
    "                      'Z: %{z:.2f}<br>' +\n",
    "                      'Cluster: %{text}<br>' +\n",
    "                      '<extra></extra>'\n",
    "    ))\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=dict(\n",
    "            text='Advanced 3D Multi-Cluster Physics Simulation<br>' +\n",
    "                      '<sub>Interactive Visualization of Higher-Dimensional Particle Distribution</sub>',\n",
    "            x=0.5,\n",
    "            font=dict(size=20, family=\"Arial Black\")\n",
    "        ),\n",
    "        scene=dict(\n",
    "            xaxis_title='X Coordinate',\n",
    "            yaxis_title='Y Coordinate', \n",
    "            zaxis_title='Z Coordinate',\n",
    "            camera_eye=dict(x=1.2, y=1.2, z=1.2)\n",
    "        ),\n",
    "        width=1000,\n",
    "        height=700,\n",
    "        margin=dict(r=20, b=10, l=10, t=80)\n",
    "    )\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# Create and display interactive 3D visualization\n",
    "interactive_fig = create_advanced_interactive_3d()\n",
    "interactive_fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Advanced Machine Learning Visualization - t-SNE and PCA Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ml_dimensionality_reduction_viz():\n",
    "    # Generate a sophisticated high-dimensional dataset\n",
    "    np.random.seed(42)\n",
    "    n_samples = 1000\n",
    "    n_features = 20\n",
    "    \n",
    "    # Create clusters in high-dimensional space\n",
    "    X = np.random.randn(n_samples, n_features)\n",
    "    \n",
    "    # Add some structure to the data\n",
    "    for i in range(0, n_samples, 100):\n",
    "        X[i:i+100] += np.random.randn(100, n_features) * 0.5\n",
    "    \n",
    "    # Apply PCA\n",
    "    pca = PCA(n_components=2)\n",
    "    X_pca = pca.fit_transform(X)\n",
    "    \n",
    "    # Apply t-SNE\n",
    "    tsne = TSNE(n_components=2, random_state=42, perplexity=30)\n",
    "    X_tsne = tsne.fit_transform(X)\n",
    "    \n",
    "    # Create comprehensive visualization\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    \n",
    "    # PCA Plot\n",
    "    scatter1 = axes[0,0].scatter(X_pca[:, 0], X_pca[:, 1], c=np.arange(n_samples), \n",
    "                                cmap='viridis', alpha=0.7, s=30)\n",
    "    axes[0,0].set_title('PCA: Principal Component Analysis\\\\n' + \n",
    "                        f'Variance Explained: {pca.explained_variance_ratio_.sum()*100:.1f}%', \n",
    "                        fontweight='bold', fontsize=14)\n",
    "    axes[0,0].set_xlabel('First Principal Component', fontweight='bold')\n",
    "    axes[0,0].set_ylabel('Second Principal Component', fontweight='bold')\n",
    "    axes[0,0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # t-SNE Plot\n",
    "    scatter2 = axes[0,1].scatter(X_tsne[:, 0], X_tsne[:, 1], c=np.arange(n_samples), \n",
    "                                cmap='plasma', alpha=0.7, s=30)\n",
    "    axes[0,1].set_title('t-SNE: Non-linear Dimensionality Reduction\\\\n' +\n",
    "                        'Advanced Pattern Recognition', \n",
    "                        fontweight='bold', fontsize=14)\n",
    "    axes[0,1].set_xlabel('t-SNE Component 1', fontweight='bold')\n",
    "    axes[0,1].set_ylabel('t-SNE Component 2', fontweight='bold')\n",
    "    axes[0,1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Variance Explained by PCA Components\n",
    "    pca_full = PCA().fit(X)\n",
    "    cumsum_var = np.cumsum(pca_full.explained_variance_ratio_)\n",
    "    \n",
    "    axes[1,0].plot(range(1, len(cumsum_var)+1), cumsum_var, 'b-', linewidth=3)\n",
    "    axes[1,0].axhline(y=0.95, color='r', linestyle='--', label='95% Variance')\n",
    "    axes[1,0].set_title('PCA: Cumulative Explained Variance\\\\n' +\n",
    "                        'Optimal Dimension Selection', \n",
    "                        fontweight='bold', fontsize=14)\n",
    "    axes[1,0].set_xlabel('Number of Components', fontweight='bold')\n",
    "    axes[1,0].set_ylabel('Cumulative Explained Variance', fontweight='bold')\n",
    "    axes[1,0].grid(True, alpha=0.3)\n",
    "    axes[1,0].legend()\n",
    "    \n",
    "    # Compare original high-dimensional space projections\n",
    "    # Use first 2 original dimensions\n",
    "    scatter4 = axes[1,1].scatter(X[:, 0], X[:, 1], c=np.arange(n_samples), \n",
    "                                cmap='coolwarm', alpha=0.7, s=30)\n",
    "    axes[1,1].set_title('Original High-Dimensional Space\\\\n' +\n",
    "                        'Feature Dimension 1 vs 2', \n",
    "                        fontweight='bold', fontsize=14)\n",
    "    axes[1,1].set_xlabel('Feature 1', fontweight='bold')\n",
    "    axes[1,1].set_ylabel('Feature 2', fontweight='bold')\n",
    "    axes[1,1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.suptitle('Advanced ML Dimensionality Reduction Analysis\\\\n' +\n",
    "                 'Professional Machine Learning Visualization Suite', \n",
    "                 fontsize=18, fontweight='bold', y=1.01)\n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "# Generate ML visualization\n",
    "ml_fig = create_ml_dimensionality_reduction_viz()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Professional Correlation and Heatmap Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_advanced_correlation_analysis():\n",
    "    # Create sophisticated correlation dataset\n",
    "    np.random.seed(42)\n",
    "    n_samples = 1000\n",
    "    \n",
    "    # Physics-inspired variables with realistic correlations\n",
    "    data = pd.DataFrame({\n",
    "        'Dimensions': np.random.uniform(1, 11, n_samples),\n",
    "        'Complexity': np.random.uniform(0.1, 1.0, n_samples),\n",
    "        'Quantization': np.random.uniform(0.0, 1.0, n_samples),\n",
    "        'Symmetry': np.random.uniform(0.0, 1.0, n_samples),\n",
    "        'Probability': np.random.uniform(0.0, 1.0, n_samples),\n",
    "        'Entropy': np.random.uniform(0.0, 1.0, n_samples),\n",
    "        'Information': np.random.uniform(0.0, 1.0, n_samples),\n",
    "        'Energy': np.random.uniform(0.0, 10.0, n_samples),\n",
    "        'Time': np.random.uniform(0.0, 100.0, n_samples)\n",
    "    })\n",
    "    \n",
    "    # Introduce realistic correlations\n",
    "    data['Probability'] = (\n",
    "        0.2 + \n",
    "        0.3 * data['Dimensions'] / 11 +\n",
    "        0.25 * data['Quantization'] +\n",
    "        0.2 * data['Information'] +\n",
    "        0.15 * data['Symmetry'] +\n",
    "        np.random.normal(0, 0.1, n_samples)  # Add noise\n",
    "    )\n",
    "    \n",
    "    # Ensure values stay within bounds\n",
    "    data['Probability'] = np.clip(data['Probability'], 0, 1)\n",
    "    \n",
    "    # Create comprehensive visualization\n",
    "    fig = plt.figure(figsize=(20, 15))\n",
    "    \n",
    "    # Main correlation heatmap\n",
    "    gs = fig.add_gridspec(3, 3, height_ratios=[1, 1, 1], width_ratios=[1, 1, 1])\n",
    "    \n",
    "    # Large correlation heatmap\n",
    "    ax1 = fig.add_subplot(gs[:, :2])\n",
    "    \n",
    "    # Calculate correlation matrix\n",
    "    corr_matrix = data.corr()\n",
    "    \n",
    "    # Create mask for upper triangle\n",
    "    mask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n",
    "    \n",
    "    sns.heatmap(corr_matrix, \n",
    "                mask=mask,\n",
    "                annot=True,\n",
    "                fmt='.2f',\n",
    "                cmap='RdBu_r',\n",
    "                center=0,\n",
    "                square=True,\n",
    "                ax=ax1,\n",
    "                cbar_kws={\"shrink\": .8, \"label\": \"Correlation Coefficient\"})\n",
    "    ax1.set_title('Advanced Physics Parameters Correlation Matrix\\\\n' +\n",
    "                  'Multi-Dimensional Simulation Analysis - Professional Grade', \n",
    "                  fontsize=16, fontweight='bold', pad=20)\n",
    "    \n",
    "    # Additional visualization in remaining space\n",
    "    ax2 = fig.add_subplot(gs[0, 2])\n",
    "    top_corr = corr_matrix['Probability'].abs().sort_values(ascending=False).head(5)[1:] # Exclude self\n",
    "    ax2.barh(top_corr.index, top_corr.values, color='steelblue', alpha=0.8)\n",
    "    ax2.set_title('Top Correlations with\\\\nSimulation Probability', fontweight='bold')\n",
    "    ax2.set_xlabel('Absolute Correlation')\n",
    "    \n",
    "    ax3 = fig.add_subplot(gs[1, 2])\n",
    "    prob_dist = data['Probability'].hist(bins=50, density=True, alpha=0.7, \n",
    "                                         color='lightcoral', edgecolor='black')\n",
    "    ax3.set_title('Probability Distribution\\\\nSimulation Results', fontweight='bold')\n",
    "    ax3.set_ylabel('Density')\n",
    "    ax3.set_xlabel('Simulation Probability')\n",
    "    \n",
    "    ax4 = fig.add_subplot(gs[2, 2])\n",
    "    # Scatter plot of top correlation\n",
    "    top_feature = top_corr.index[0]\n",
    "    ax4.scatter(data[top_feature], data['Probability'], alpha=0.6, s=30)\n",
    "    ax4.set_title(f'Probability vs {top_feature}\\\\nStrongest Correlation', fontweight='bold')\n",
    "    ax4.set_xlabel(top_feature)\n",
    "    ax4.set_ylabel('Simulation Probability')\n",
    "    \n",
    "    plt.suptitle('Advanced Correlation Analysis Dashboard\\\\n' +\n",
    "                 'Professional ML Research Visualizations', \n",
    "                 fontsize=20, fontweight='bold', y=0.98)\n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "# Generate correlation analysis\n",
    "corr_fig = create_advanced_correlation_analysis()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "## Professional ML/DL Visualization Suite Created\n",
    "\n",
    "This notebook demonstrates world-class machine learning visualization techniques including:\n",
    "\n",
    "1. **Advanced 3D Surface Plots** - Complex mathematical relationships\n",
    "2. **Quantum Field Simulations** - Multi-dimensional particle physics\n",
    "3. **Interactive 3D Visualizations** - Plotly-powered professional dashboards\n",
    "4. **ML Dimensionality Reduction** - PCA and t-SNE analysis\n",
    "5. **Advanced Correlation Analysis** - Professional-grade heatmaps\n",
    "\n",
    "These visualizations represent the pinnacle of ML research presentation, suitable for publication in top-tier journals or presentation at major conferences."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}